{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762bc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ad9bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path('/home/team/data/pmt_pmt/raw/training_data.csv')\n",
    "TEST_PATH = Path('/home/team/data/pmt_pmt/raw/testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2cca098",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10237a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates()\n",
    "test_df = test_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25d50ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = test_df.merge(train_df, on=['Antigen', 'HLA', 'CDR3'], how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff870d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[~test_df.index.isin(merged_df[merged_df['_merge'] == 'both'].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88a0316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def generate_triplet_negatives(\n",
    "    df: pd.DataFrame,\n",
    "    pep_col: str = \"Antigen\",\n",
    "    mhc_col: str = \"HLA\",\n",
    "    tcr_col: str = \"CDR3\",\n",
    "    k: int = 1,\n",
    "    seed: int = 42,\n",
    "    max_tries_per_sample: int = 50,\n",
    "    return_with_labels: bool = True,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Для каждого уникального пептида сэмплирует k случайных (HLA, TCR) на КАЖДУЮ его позитивную строку,\n",
    "    избегая комбинаций, которые уже встречались с этим пептидом в df.\n",
    "\n",
    "    Возвращает:\n",
    "      negatives_df: DataFrame с колонками [pep_col, mhc_col, tcr_col] (+ 'label'=0 если return_with_labels)\n",
    "      optionally: объединённый df с позитивами (label=1) и негативами (label=0), если return_with_labels=True\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # все уникальные значения для глобального сэмплинга\n",
    "    all_mhc = df[mhc_col].unique()\n",
    "    all_tcr = df[tcr_col].unique()\n",
    "\n",
    "    # для каждого пептида — множество уже встречавшихся пар (mhc, tcr)\n",
    "    seen_pairs_by_pep = {\n",
    "        pep: set(zip(g[mhc_col].tolist(), g[tcr_col].tolist()))\n",
    "        for pep, g in df.groupby(pep_col, sort=False)\n",
    "    }\n",
    "\n",
    "    neg_rows = []\n",
    "    for pep, g in df.groupby(pep_col, sort=False):\n",
    "        n_pos = len(g)\n",
    "        need = n_pos * k\n",
    "\n",
    "        seen_pairs = set(seen_pairs_by_pep[pep])  # нельзя брать отсюда\n",
    "        chosen_pairs = set()                      # и не повторяться в негативных для этого pep\n",
    "\n",
    "        tries = 0\n",
    "        # rejection sampling: случайно берём mhc и tcr пока не наберём need штук\n",
    "        while len(chosen_pairs) < need and tries < need * max_tries_per_sample:\n",
    "            mhc = rng.choice(all_mhc)\n",
    "            tcr = rng.choice(all_tcr)\n",
    "            pair = (mhc, tcr)\n",
    "            if pair not in seen_pairs and pair not in chosen_pairs:\n",
    "                chosen_pairs.add(pair)\n",
    "            tries += 1\n",
    "\n",
    "        if len(chosen_pairs) < need:\n",
    "            # если данных мало (например, один MHC и один TCR у pep), предупреждаем\n",
    "            print(f\"[warn] For peptide '{pep}' generated {len(chosen_pairs)}/{need} negatives \"\n",
    "                  f\"(increase max_tries_per_sample or provide more diversity).\")\n",
    "\n",
    "        for mhc, tcr in chosen_pairs:\n",
    "            neg_rows.append({pep_col: pep, mhc_col: mhc, tcr_col: tcr})\n",
    "\n",
    "    negatives_df = pd.DataFrame(neg_rows, columns=[pep_col, mhc_col, tcr_col])\n",
    "\n",
    "    if return_with_labels:\n",
    "        pos = df.copy()\n",
    "        pos[\"label\"] = 1\n",
    "        neg = negatives_df.copy()\n",
    "        neg[\"label\"] = 0\n",
    "        combined = pd.concat([pos, neg], ignore_index=True)\n",
    "        return combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd46d950",
   "metadata": {},
   "source": [
    "Ratio 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afb79f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_labeled = generate_triplet_negatives(train_df)\n",
    "test_df_labeled = generate_triplet_negatives(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f816f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataFromDF:\n",
    "    \"\"\"\n",
    "    Принимает готовый pd.DataFrame с колонками:\n",
    "      Antigen, HLA, CDR3, label\n",
    "    Строит HeteroData граф для задачи p-m-t.\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.pid = {}\n",
    "        self.mid = {}\n",
    "        self.tid = {}\n",
    "        self.data = None  # HeteroData\n",
    "\n",
    "    def build_id_maps(self):\n",
    "        all_p = pd.Index(self.df[\"Antigen\"].unique())\n",
    "        all_m = pd.Index(self.df[\"HLA\"].unique())\n",
    "        all_t = pd.Index(self.df[\"CDR3\"].unique())\n",
    "        self.pid = {v: i for i, v in enumerate(all_p)}\n",
    "        self.mid = {v: i for i, v in enumerate(all_m)}\n",
    "        self.tid = {v: i for i, v in enumerate(all_t)}\n",
    "\n",
    "    def build_graph(self) -> HeteroData:\n",
    "        data = HeteroData()\n",
    "        data[\"pep\"].num_nodes = len(self.pid)\n",
    "        data[\"mhc\"].num_nodes = len(self.mid)\n",
    "        data[\"tcr\"].num_nodes = len(self.tid)\n",
    "\n",
    "        # P-M edges\n",
    "        pm_edges = [(self.pid[p], self.mid[m]) for p, m in zip(self.df[\"Antigen\"], self.df[\"HLA\"])]\n",
    "        data[\"pep\", \"binds\", \"mhc\"].edge_index = torch.tensor(pm_edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # M-T edges\n",
    "        mt_edges = [(self.mid[m], self.tid[t]) for m, t in zip(self.df[\"HLA\"], self.df[\"CDR3\"])]\n",
    "        data[\"mhc\", \"presents_to\", \"tcr\"].edge_index = torch.tensor(mt_edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # Triplet tensors + split\n",
    "        y_pmt = torch.tensor(self.df[\"label\"].astype(\"int64\").values)\n",
    "        tr, te = train_test_split(\n",
    "            np.arange(len(self.df)),\n",
    "            test_size=0.2, random_state=42, stratify=self.df[\"label\"].values\n",
    "        )\n",
    "        data[\"pmt_splits\"] = {\"train\": torch.tensor(tr), \"test\": torch.tensor(te)}\n",
    "        data[\"pmt_pairs\"] = {\n",
    "            \"pep\": torch.tensor([self.pid[p] for p in self.df[\"Antigen\"].values], dtype=torch.long),\n",
    "            \"mhc\": torch.tensor([self.mid[m] for m in self.df[\"HLA\"].values], dtype=torch.long),\n",
    "            \"tcr\": torch.tensor([self.tid[t] for t in self.df[\"CDR3\"].values], dtype=torch.long),\n",
    "            \"y\":   y_pmt,\n",
    "        }\n",
    "\n",
    "        self.data = data\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48277617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletOnlyGNN(nn.Module):\n",
    "    def __init__(self, n_pep, n_mhc, n_tcr, emb_dim=128, hidden=256, layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.emb = nn.ModuleDict({\n",
    "            \"pep\": nn.Embedding(n_pep, emb_dim),\n",
    "            \"mhc\": nn.Embedding(n_mhc, emb_dim),\n",
    "            \"tcr\": nn.Embedding(n_tcr, emb_dim),\n",
    "        })\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(layers):\n",
    "            self.layers.append(HeteroConv({\n",
    "                (\"pep\",\"binds\",\"mhc\"): SAGEConv((-1,-1), hidden),\n",
    "                (\"mhc\",\"presents_to\",\"tcr\"): SAGEConv((-1,-1), hidden),\n",
    "            }, aggr=\"mean\"))\n",
    "\n",
    "        # НОВОЕ: проекции в общий размер hidden\n",
    "        self.proj_pep = nn.Linear(emb_dim, hidden)\n",
    "        self.proj_mhc = nn.Identity()   # уже hidden после конвов\n",
    "        self.proj_tcr = nn.Identity()   # уже hidden после конвов\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(3*hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "\n",
    "    def _forward_node_embeddings(self, data):\n",
    "        device = self.emb[\"pep\"].weight.device\n",
    "        h = {\n",
    "            \"pep\": self.emb[\"pep\"](torch.arange(data[\"pep\"].num_nodes, device=device)),\n",
    "            \"mhc\": self.emb[\"mhc\"](torch.arange(data[\"mhc\"].num_nodes, device=device)),\n",
    "            \"tcr\": self.emb[\"tcr\"](torch.arange(data[\"tcr\"].num_nodes, device=device)),\n",
    "        }\n",
    "        edge_index_dict = {\n",
    "            (\"pep\",\"binds\",\"mhc\"): data[\"pep\",\"binds\",\"mhc\"].edge_index,\n",
    "            (\"mhc\",\"presents_to\",\"tcr\"): data[\"mhc\",\"presents_to\",\"tcr\"].edge_index,\n",
    "        }\n",
    "        for conv in self.layers:\n",
    "            out = conv(h, edge_index_dict)\n",
    "            out = {k: F.dropout(F.relu(v), p=self.dropout, training=self.training) for k,v in out.items()}\n",
    "            # сохраняем представления для типов, которых нет в out (pep)\n",
    "            h = {k: out.get(k, h[k]) for k in h.keys()}\n",
    "        return h\n",
    "\n",
    "    def forward_scores(self, data, pairs):\n",
    "        h = self._forward_node_embeddings(data)\n",
    "        # приведение всех трёх к hidden\n",
    "        hp = self.proj_pep(h[\"pep\"])[pairs[\"pep\"]]\n",
    "        hm = self.proj_mhc(h[\"mhc\"])[pairs[\"mhc\"]]\n",
    "        ht = self.proj_tcr(h[\"tcr\"])[pairs[\"tcr\"]]\n",
    "        logits = self.head(torch.cat([hp, hm, ht], dim=-1)).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e577d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    seed: int = 42\n",
    "\n",
    "    # model\n",
    "    emb_dim: int = 128\n",
    "    hidden: int = 256\n",
    "    layers: int = 2\n",
    "    dropout: float = 0.2\n",
    "\n",
    "    # training\n",
    "    epochs: int = 10\n",
    "    lr: float = 2e-3\n",
    "    weight_decay: float = 1e-4\n",
    "\n",
    "    device: str = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "73cbdcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def metrics_bin(y_true: np.ndarray, y_score: np.ndarray) -> Dict[str, float]:\n",
    "    return {\n",
    "        \"roc_auc\": float(roc_auc_score(y_true, y_score)),\n",
    "        \"pr_auc\": float(average_precision_score(y_true, y_score)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50a227cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, cfg: Config, data: HeteroData):\n",
    "        self.cfg = cfg\n",
    "        self.device = torch.device(cfg.device if torch.cuda.is_available() else \"cpu\")\n",
    "        self.data = data\n",
    "\n",
    "        n_pep = data[\"pep\"].num_nodes\n",
    "        n_mhc = data[\"mhc\"].num_nodes\n",
    "        n_tcr = data[\"tcr\"].num_nodes\n",
    "\n",
    "        self.model = TripletOnlyGNN(\n",
    "            n_pep, n_mhc, n_tcr,\n",
    "            emb_dim=cfg.emb_dim, hidden=cfg.hidden, layers=cfg.layers, dropout=cfg.dropout\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.opt = torch.optim.AdamW(self.model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "        # move static graph tensors\n",
    "        for et in [(\"pep\", \"binds\", \"mhc\"), (\"mhc\", \"presents_to\", \"tcr\")]:\n",
    "            data[et].edge_index = data[et].edge_index.to(self.device)\n",
    "        for kk, v in data[\"pmt_pairs\"].items():\n",
    "            data[\"pmt_pairs\"][kk] = v.to(self.device)\n",
    "        for kk, v in data[\"pmt_splits\"].items():\n",
    "            data[\"pmt_splits\"][kk] = v.to(self.device)\n",
    "\n",
    "    def _bce(self, logits, y):\n",
    "        return F.binary_cross_entropy_with_logits(logits, y.float())\n",
    "\n",
    "    def _run_split(self, split: str) -> Dict[str, float]:\n",
    "        model, data = self.model, self.data\n",
    "        is_train = split == \"train\"\n",
    "        model.train() if is_train else model.eval()\n",
    "\n",
    "        idx = data[\"pmt_splits\"][split]\n",
    "        pairs_full = data[\"pmt_pairs\"]\n",
    "        pairs = {\"pep\": pairs_full[\"pep\"][idx],\n",
    "                 \"mhc\": pairs_full[\"mhc\"][idx],\n",
    "                 \"tcr\": pairs_full[\"tcr\"][idx]}\n",
    "        y = pairs_full[\"y\"][idx]\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            logits = model.forward_scores(data, pairs)\n",
    "            loss = self._bce(logits, y)\n",
    "\n",
    "            if is_train:\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "\n",
    "        return {\"loss\": float(loss.detach().item())}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self) -> Dict[str, float]:\n",
    "        model, data = self.model, self.data\n",
    "        model.eval()\n",
    "        idx = data[\"pmt_splits\"][\"test\"]\n",
    "\n",
    "        pairs_full = data[\"pmt_pairs\"]\n",
    "        pairs = {\"pep\": pairs_full[\"pep\"][idx],\n",
    "                 \"mhc\": pairs_full[\"mhc\"][idx],\n",
    "                 \"tcr\": pairs_full[\"tcr\"][idx]}\n",
    "        y = pairs_full[\"y\"][idx].detach().cpu().numpy()\n",
    "        logits = model.forward_scores(data, pairs)\n",
    "        scores = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        return metrics_bin(y, scores)\n",
    "\n",
    "    def fit(self):\n",
    "        for epoch in range(1, self.cfg.epochs + 1):\n",
    "            tl = self._run_split(\"train\")\n",
    "            vl = self._run_split(\"test\")\n",
    "            m = self.evaluate()\n",
    "            print(json.dumps({\"epoch\": epoch, \"train\": tl, \"val\": vl, \"metrics\": m}, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fab20ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cfg = Config()\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    # load data & build graph\n",
    "    ds = TripletDataFromDF(train_df_labeled)\n",
    "    ds.build_id_maps()\n",
    "    data = ds.build_graph()\n",
    "\n",
    "    # train\n",
    "    trainer = Trainer(cfg, data)\n",
    "    trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86b41344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/team/anaconda3/envs/unipmt/lib/python3.11/site-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'pep'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"epoch\": 1, \"train\": {\"loss\": 0.6944091320037842}, \"val\": {\"loss\": 0.6412291526794434}, \"metrics\": {\"roc_auc\": 0.942475703596567, \"pr_auc\": 0.9320037671124302}}\n",
      "{\"epoch\": 2, \"train\": {\"loss\": 0.6362224221229553}, \"val\": {\"loss\": 0.5510789752006531}, \"metrics\": {\"roc_auc\": 0.9547503072394423, \"pr_auc\": 0.9482793968513583}}\n",
      "{\"epoch\": 3, \"train\": {\"loss\": 0.5571649074554443}, \"val\": {\"loss\": 0.45060911774635315}, \"metrics\": {\"roc_auc\": 0.9510077042109826, \"pr_auc\": 0.9517305436737268}}\n",
      "{\"epoch\": 4, \"train\": {\"loss\": 0.4625527858734131}, \"val\": {\"loss\": 0.3511071503162384}, \"metrics\": {\"roc_auc\": 0.9612361028900442, \"pr_auc\": 0.9540453536434291}}\n",
      "{\"epoch\": 5, \"train\": {\"loss\": 0.35303109884262085}, \"val\": {\"loss\": 0.27104517817497253}, \"metrics\": {\"roc_auc\": 0.963222032890434, \"pr_auc\": 0.9573624416574291}}\n",
      "{\"epoch\": 6, \"train\": {\"loss\": 0.2813451588153839}, \"val\": {\"loss\": 0.2215682715177536}, \"metrics\": {\"roc_auc\": 0.9692280150858612, \"pr_auc\": 0.9627079597090946}}\n",
      "{\"epoch\": 7, \"train\": {\"loss\": 0.2266571819782257}, \"val\": {\"loss\": 0.2026720643043518}, \"metrics\": {\"roc_auc\": 0.9744494632056195, \"pr_auc\": 0.9666207209053274}}\n",
      "{\"epoch\": 8, \"train\": {\"loss\": 0.20574045181274414}, \"val\": {\"loss\": 0.18476732075214386}, \"metrics\": {\"roc_auc\": 0.9772220483947605, \"pr_auc\": 0.9652465520856275}}\n",
      "{\"epoch\": 9, \"train\": {\"loss\": 0.19434207677841187}, \"val\": {\"loss\": 0.17869409918785095}, \"metrics\": {\"roc_auc\": 0.9813396591659141, \"pr_auc\": 0.9733191332540163}}\n",
      "{\"epoch\": 10, \"train\": {\"loss\": 0.17853949964046478}, \"val\": {\"loss\": 0.17256015539169312}, \"metrics\": {\"roc_auc\": 0.9820967450282434, \"pr_auc\": 0.9757905451334827}}\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf7d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
